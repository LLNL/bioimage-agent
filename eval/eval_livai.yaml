providers:
  - id: python:general_mcp_client.py
    config:
      cache: false
      provider: litellm
      model: gpt-4o
      baseUrl: https://livai-api.llnl.gov/v1
      verifySSL: false
      useProxy: false
           
      mcp:
        enabled: true
        server:
          command: "C:/Users/miao1/AppData/Local/anaconda3/envs/mcp/python.exe"
          args: ["-u", "D:/Development/napari-mcp/src/napari_mcp/napari_mcp_server.py"]
          cwd: "D:/Development/napari-mcp/eval"
          name: napari-server
          env:
            PORT: "3000"        
        temperature: 0
        # max_tokens: 4096
        executeTools: true

prompts:
  - |
    {{question}}

# Configure default test settings for model-graded assertions
defaultTest:
  options:
    # Override the default provider for model-graded assertions
    provider:
      id: litellm:gpt-4o
      config:
        apiBaseUrl: https://livai-api.llnl.gov/v1
        # For OpenAI-compatible endpoints served by LiteLLM
        openaiCompatible: true
        verifySSL: false
        useProxy: false

tests: 
  #- file://tasks/0_actions/eval_basic_napari_functions.yaml
  #- file://tasks/1_workflows/multi_channel_visualization/eval_visualization_workflows.yaml
  #- file://tasks/1_workflows/eval_iso_surface_determination.yaml
  - file://tasks/1_workflows/eval_figure_recreation.yaml

evaluateOptions:
  cache: false
  maxConcurrency: 1    